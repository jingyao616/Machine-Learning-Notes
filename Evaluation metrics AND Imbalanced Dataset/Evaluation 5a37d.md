# Evaluation metrics AND Imbalanced Dataset

# Evaluation metrics (for classification models)

### Accuracy

- Total correct / Total observations

### Precision

- 
    
    ![Screen Shot 2022-03-11 at 1.32.11 AM.png](Evaluation%205a37d/Screen_Shot_2022-03-11_at_1.32.11_AM.png)
    
    ![Screen Shot 2022-03-11 at 1.29.34 AM.png](Evaluation%205a37d/Screen_Shot_2022-03-11_at_1.29.34_AM.png)
    

### Recall

- ä¹Ÿå«Sensitivityï¼
- ä¹Ÿå«True Positive Rate (TPR) åœ¨ROCæ›²çº¿é‡Œçš„ç«–è½´ï¼
    
    ![Screen Shot 2022-03-11 at 1.33.25 AM.png](Evaluation%205a37d/Screen_Shot_2022-03-11_at_1.33.25_AM.png)
    
    ![Screen Shot 2022-03-11 at 1.33.47 AM.png](Evaluation%205a37d/Screen_Shot_2022-03-11_at_1.33.47_AM.png)
    

### F1

F1 Score is balance between Precision and Recall

<aside>
ğŸ’¡ Note: å†æŸç§ç‰¹å®šæƒ…å†µä¸‹ï¼Œæ¯”å¦‚Class Aæ˜¯æœ‰ç—…ï¼ŒClass Bæ˜¯æ²¡ç—…ï¼Œé‚£å®æ„¿æŠŠæ²¡ç—…è¯´æˆæœ‰ç—…ï¼Œä¹Ÿä¸èƒ½é”™è¿‡ä¸€ä¸ªç—…äººã€‚ä¹Ÿå°±æ˜¯æƒ³avoid class A as Bï¼Œé‚£å°±è¦ Recallé«˜ä¸€äº›çš„modelã€‚

</aside>

## [Confusion Matrices:](https://www.youtube.com/watch?v=Kdsp6soqA7o)

![Untitled](Evaluation%205a37d/Untitled.png)